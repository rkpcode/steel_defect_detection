{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dab31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COLAB MEMORY-EFFICIENT COMPLETE PIPELINE\n",
    "=========================================\n",
    "Steel Defect Detection System\n",
    "\n",
    "Run this entire notebook in Google Colab.\n",
    "Each cell should be run sequentially.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff678f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 1: SETUP & CLONE\n",
    "# ============================================\n",
    "\"\"\"\n",
    "# Run in Colab:\n",
    "!git clone https://github.com/rkpcode/steel_defect_detection.git\n",
    "%cd /content/steel_defect_detection\n",
    "!pip install -q albumentations gdown kaggle\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 2: KAGGLE DATA DOWNLOAD\n",
    "# ============================================\n",
    "\"\"\"\n",
    "# Upload kaggle.json first, then run:\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c severstal-steel-defect-detection -p artifacts/data/raw\n",
    "!cd artifacts/data/raw && unzip -q severstal-steel-defect-detection.zip\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 3: DATA PIPELINE (Memory Efficient)\n",
    "# ============================================\n",
    "\"\"\"\n",
    "# Run data ingestion and transformation\n",
    "!python run_pipeline.py --skip-training --memory-efficient\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420abb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 4: MEMORY-EFFICIENT TRAINING\n",
    "# ============================================\n",
    "import sys\n",
    "sys.path.insert(0, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ce209",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MEMORY-EFFICIENT TRAINING\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd76e9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Custom metrics\n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred)\n",
    "    fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "    fn = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "    precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "    recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "    return (5 * precision * recall) / (4 * precision + recall + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0adfc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "train_meta = pd.read_csv('artifacts/data/patches/train/train_metadata.csv')\n",
    "test_meta = pd.read_csv('artifacts/data/patches/test/test_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fab2ac",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(f\"Train patches: {len(train_meta)}\")\n",
    "print(f\"Test patches: {len(test_meta)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d66d2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Generator for memory-efficient loading\n",
    "def data_generator(meta_df, batch_size=32, shuffle=True):\n",
    "    indices = np.arange(len(meta_df))\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch_idx = indices[start:start+batch_size]\n",
    "            batch_paths = meta_df['file_path'].values[batch_idx]\n",
    "            batch_labels = meta_df['label'].values[batch_idx]\n",
    "            \n",
    "            X_batch = np.array([np.load(p) for p in batch_paths])\n",
    "            y_batch = np.array(batch_labels, dtype=np.float32)\n",
    "            \n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043c990",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def create_model():\n",
    "    base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "    base.trainable = False  # Freeze for transfer learning\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        base,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc'), \n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall'),\n",
    "                 f2_score]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597791d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6096d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights\n",
    "n_defective = train_meta['label'].sum()\n",
    "n_clean = len(train_meta) - n_defective\n",
    "class_weight = {0: len(train_meta)/(2*n_clean), 1: len(train_meta)/(2*n_defective)}\n",
    "print(f\"Class weights: {class_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b052f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "os.makedirs('artifacts/models', exist_ok=True)\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'artifacts/models/transfer_model_best.keras',\n",
    "        monitor='val_recall', mode='max', save_best_only=True, verbose=1\n",
    "    ),\n",
    "    callbacks.EarlyStopping(monitor='val_recall', mode='max', patience=5, verbose=1),\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_recall', mode='max', factor=0.5, patience=2, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4bb71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "steps_per_epoch = len(train_meta) // BATCH_SIZE\n",
    "validation_steps = len(test_meta) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nStarting training...\")\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4239835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "history = model.fit(\n",
    "    data_generator(train_meta, BATCH_SIZE, shuffle=True),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=data_generator(test_meta, BATCH_SIZE, shuffle=False),\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebdad00",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save('artifacts/models/transfer_model_final.keras')\n",
    "print(\"\\nTraining complete! Models saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 5: MEMORY-EFFICIENT EVALUATION\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MEMORY-EFFICIENT EVALUATION\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c210b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = keras.models.load_model(\n",
    "    'artifacts/models/transfer_model_best.keras',\n",
    "    custom_objects={'f2_score': f2_score}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch prediction\n",
    "test_meta = pd.read_csv('artifacts/data/patches/test/test_metadata.csv')\n",
    "y_test = test_meta['label'].values\n",
    "y_pred_proba = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating predictions...\")\n",
    "for i in range(0, len(test_meta), 200):\n",
    "    batch_paths = test_meta['file_path'].values[i:i+200]\n",
    "    X_batch = np.array([np.load(p) for p in batch_paths])\n",
    "    preds = model.predict(X_batch, verbose=0).flatten()\n",
    "    y_pred_proba.extend(preds)\n",
    "    del X_batch\n",
    "    gc.collect()\n",
    "    if i % 2000 == 0:\n",
    "        print(f\"Progress: {i}/{len(test_meta)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a371ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = np.array(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold\n",
    "print(\"\\nFinding optimal threshold...\")\n",
    "best_recall = 0\n",
    "best_thresh = 0.5\n",
    "best_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for thresh in np.arange(0.1, 0.9, 0.05):\n",
    "    y_pred = (y_pred_proba >= thresh).astype(int)\n",
    "    tp = sum((y_test == 1) & (y_pred == 1))\n",
    "    fn = sum((y_test == 1) & (y_pred == 0))\n",
    "    fp = sum((y_test == 0) & (y_pred == 1))\n",
    "    tn = sum((y_test == 0) & (y_pred == 0))\n",
    "    \n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    \n",
    "    if recall > best_recall and recall < 1.0:\n",
    "        best_recall = recall\n",
    "        best_thresh = thresh\n",
    "        best_metrics = {'tp': tp, 'fn': fn, 'fp': fp, 'tn': tn, \n",
    "                       'recall': recall, 'precision': precision}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "========================================\n",
    "EVALUATION RESULTS\n",
    "========================================\n",
    "Total Test Patches: {len(y_test)}\n",
    "Defective: {sum(y_test)}\n",
    "\n",
    "Optimal Threshold: {best_thresh:.2f}\n",
    "\n",
    "Confusion Matrix:\n",
    "  TP: {best_metrics.get('tp', 0)}, FP: {best_metrics.get('fp', 0)}\n",
    "  FN: {best_metrics.get('fn', 0)}, TN: {best_metrics.get('tn', 0)}\n",
    "\n",
    "Metrics:\n",
    "  Recall: {best_metrics.get('recall', 0):.4f} ({best_metrics.get('recall', 0)*100:.1f}%)\n",
    "  Precision: {best_metrics.get('precision', 0):.4f}\n",
    "  \n",
    "Missed Defects (FN): {best_metrics.get('fn', 0)}\n",
    "False Alarms (FP): {best_metrics.get('fp', 0)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887941e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open('artifacts/evaluation/full_evaluation_results.txt', 'w') as f:\n",
    "    f.write(f\"\"\"Full Dataset Evaluation Results\n",
    "================================\n",
    "Total Patches: {len(y_test)}\n",
    "Defective: {sum(y_test)}\n",
    "Optimal Threshold: {best_thresh}\n",
    "Recall: {best_metrics.get('recall', 0):.4f}\n",
    "Precision: {best_metrics.get('precision', 0):.4f}\n",
    "TP: {best_metrics.get('tp', 0)}\n",
    "FN: {best_metrics.get('fn', 0)}\n",
    "FP: {best_metrics.get('fp', 0)}\n",
    "TN: {best_metrics.get('tn', 0)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e7d87",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d1143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 6: DOWNLOAD RESULTS\n",
    "# ============================================\n",
    "\"\"\"\n",
    "# Run in Colab:\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Download model\n",
    "files.download('artifacts/models/transfer_model_best.keras')\n",
    "\n",
    "# Download evaluation results\n",
    "shutil.make_archive('results', 'zip', 'artifacts/evaluation')\n",
    "files.download('results.zip')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
